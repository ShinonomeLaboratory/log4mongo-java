# 无痛的集中化日志管理方案——Log4mongo东云研究所特制版

## 简介
无论是公司内的日志管理还是我自己的项目，目前都依赖于Log4j，而Log4j的输出方式主要也就是文件. 控制台和socket，其实这个是不能满足使用的。尤其是系统满天星状分布的时候，或者是像Spark那样一下分身一大堆的时候（注：Spark的日志是可以集中的，但是查看起来眼睛要瞎了啊）原始的日志管理方式就显得捉襟见肘，输入tail -f查看日志已经成为了伤害我们手指最多的操作。

这个时候，一些解决方案就出来了，比如Splunk，号称能自动分析日志（中的日期之类），但是要知道，这些日志在内存里的时候本来就是组织好的，何必再去解析格式化的信息呢？直接存储到数据库中就好了啊。

之所以一开始考虑用MongoDB，是考虑了这几个优点：

1. 速度快
2. 支持分片，数据量可以很大
3. 有TTL，可以自动删除过期日志
4. 支持非结构化的数据存储

## 现有的解决方案

随后我就找到了这个项目：(RobertStewart/log4mongo-java)[https://github.com/RobertStewart/log4mongo-java]

这个项目我可以说是很满意了，写的文档比较全（但是官网打不开）。
缺点也有，这就是为什么我做了一个东云研究所的特制版，东云版解决了几个小问题（看上去小，一半代码已经改的面目全非了），使用的时候更舒服，更加无痛。

## 东云版优点

1. <del>支持批量写入，批量写入和单独写入的效率是不一样的，批量写入带来的日志延迟也考虑了，每秒都会检查缓冲区，防止积压。</del>
2. 支持超时自动删除，而且支持为不同的日志等级设置不同的保留时间。
3. 支持自动化索引创建，支持自定义索引和索引类型，原作中没有索引，这样查询可能会比较慢。
4. 支持通过日期、月份、小时或者自定义的字段对collection进行分隔，因为MongoDB是以Collection为单位存储文件的，这样存储可以防止单个Collection过大导致的索引缓慢问题。
5. 原作中使用旧版的数据类型，东云版统一使用Document作为数据类型。
6. 支持在传输过程中对数据进行压缩，减少网络流量。
7. 使用缓冲区预存数据，写入失败的时候不丢日志，遇到网络闪断之类的问题也不用担心日志丢失（请在配置文件中设置WriteConcern，在写入失败的时候抛出异常）。
8. 优化了鉴权部分，防止因为日志数据库并非鉴权数据库造成的错误。
9. 解决了原版中由于MongoDB Driver自带日志导致的冲突问题。
10. 自动尝试JSON化Message字段。

之所以说无痛，是因为日志系统是一个如跗骨之蛆的. 在设计之初就绑定在程序上的. 难以更换的系统。
而Java中，log4j可以说是用的最多的日志后端了，这个时候只需要修改log4j.properties文件，增加一个appender就能做到日志集中化的管理。
可以说几乎是完全无痛了。

## 展望

当然缺点也是有的，主要是对消息队列没有支持，其实很多时候日志是要推送显示的，更新数据库的同时应该先推送到需要看的地方，现在要更新查看日志还只能轮询。或者仍然使用以前的方式。

出于这个角度，我考虑在前面架设一个Kafka/RabbitMQ，但是这样架构就太复杂了，日后我可能为单独开发一版针对复杂场景下的使用消息队列的日志系统。

如果以后有时间，我可能再做一版Python的，还会用Python3+Django2做一版日志分析. 搜索. 格式化浏览和统计报表输出的工具，让运维也变得无痛起来。

至于为什么使用东云研究所作为名称，并不是我在东云研究所，而是我喜欢看日常，如果以后我有钱了，我就成立一个真正的东云研究所专门研究乱七八糟的黑科技和脑洞科技。
